{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL project trial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBxb3LHOh6gl"
      },
      "source": [
        "# Deep Learning Project\n",
        "\n",
        "Task Description - Find the whether the sentence has irony or not. The dataset has label 1 as irony and label 0 as not irony. \n",
        "\n",
        "To run the code- upload the data.csv, data with emoji.csv , data with hashtag and emoji.csv on the local drive of the colab to run the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJEc-qy9HdQq"
      },
      "source": [
        "# Using NAIVE BAYES and SVM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bwzhUsZ4VYH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-t1KC8aCSUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ce9169-1a3b-4d47-cd5a-5fef2fee0e16"
      },
      "source": [
        "df = pd.read_csv(r\"/content/data.csv\", encoding='latin-1')\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3817, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vEJTfyiQ7WaX",
        "outputId": "18b275a9-b1cb-4287-d8e6-0cb01f4136f8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Sweet United Nations video. Just in time for C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left I'm dying over here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                               Text\n",
              "0      1  Sweet United Nations video. Just in time for C...\n",
              "1      1  @mrdahl87 We are rumored to have talked to Erv...\n",
              "2      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
              "3      0                3 episodes left I'm dying over here\n",
              "4      1  I can't breathe! was chosen as the most notabl..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2pZkLhH7YRv"
      },
      "source": [
        "np.random.seed(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w_g3W-CcGHGA",
        "outputId": "2da03585-83a7-4f1f-bafa-11dc416ac93b"
      },
      "source": [
        "df['Text'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sweet United Nations video. Just in time for Christmas. #imagine #NoReligion  http://t.co/fej2v3OUBR'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9Wyg2E4FMhJ",
        "outputId": "e6a7846b-14d8-4bf0-b9fd-6da7c686bd72"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zmRq-F_CqmG"
      },
      "source": [
        "# conversion of words into lower case\n",
        "df['Text'] = [entry.lower() for entry in df['Text']]\n",
        "\n",
        "# Tokenization of words\n",
        "df['Text']= [word_tokenize(entry) for entry in df['Text']]\n",
        "# Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(df['Text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    df.loc[index,'text_final'] = str(Final_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1YWq5KoC6ef"
      },
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['text_final'],df['Label'],test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1bNhc_bGxtC"
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ku9RGihG1R0"
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(df['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3yX5EQw1W-B",
        "outputId": "267f5266-b656-4f58-d048-9f170fe013e8"
      },
      "source": [
        "pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQp-seFb2Gh6"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KgGZCQIG4mK",
        "outputId": "41a92621-b5f9-4cb7-9d58-2c65f282e46e"
      },
      "source": [
        "Naive = MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy Score ->  64.52879581151832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ipFSJVzKEx5",
        "outputId": "834933e1-33aa-48e7-f028-58bd82a1b02f"
      },
      "source": [
        "Naive = MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
        "\n",
        "print(classification_report(Test_Y, predictions_NB ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy Score ->  64.52879581151832\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.64      0.64       373\n",
            "           1       0.65      0.65      0.65       391\n",
            "\n",
            "    accuracy                           0.65       764\n",
            "   macro avg       0.65      0.65      0.65       764\n",
            "weighted avg       0.65      0.65      0.65       764\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDg-vOMMHAiD",
        "outputId": "8dfd0630-9ab8-447f-a77d-237de3de6535"
      },
      "source": [
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.2, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
        "\n",
        "print(classification_report(Test_Y, predictions_SVM ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy Score ->  62.82722513089005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.63      0.62       373\n",
            "           1       0.64      0.62      0.63       391\n",
            "\n",
            "    accuracy                           0.63       764\n",
            "   macro avg       0.63      0.63      0.63       764\n",
            "weighted avg       0.63      0.63      0.63       764\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmwJzVDrb_Mj"
      },
      "source": [
        "# Importing the required datasets and packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpbM98MgzMx5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkI1obmjzaA_"
      },
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJ6G7yBzZ-C"
      },
      "source": [
        "'''dataframe = pd.read_csv(r\"/content/data.txt\",delimiter=\"\\t\")\n",
        "dataframe.to_csv(\"data.csv\", encoding='utf-8', index=False)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAYoiwBwzO00",
        "outputId": "5936e4f2-6809-43be-f8a5-8876d6f5cd5d"
      },
      "source": [
        "df = pd.read_csv(r\"/content/data.csv\", encoding='latin-1')\n",
        "df.columns = ['label','text']\n",
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3816, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EDD8Qk4yzlEc",
        "outputId": "d7f6b781-711f-4224-bf65-a6b9568d5d5a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left I'm dying over here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>You're never too old for Footie Pajamas. http:...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1  @mrdahl87 We are rumored to have talked to Erv...\n",
              "1      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
              "2      0                3 episodes left I'm dying over here\n",
              "3      1  I can't breathe! was chosen as the most notabl...\n",
              "4      0  You're never too old for Footie Pajamas. http:..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO_yTV9jzlaN"
      },
      "source": [
        "np.random.seed(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4X0olUsfznl7",
        "outputId": "410aad56-60b4-440b-b252-50ad93cfd367"
      },
      "source": [
        "df['text'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@mrdahl87 We are rumored to have talked to Erv's agent... and the Angels asked about Ed Escobar... that's hardly nothing    ;)\""
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3pwSvxzpgG"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lci4Og5CzrXr"
      },
      "source": [
        "# conversion of words into lower case\n",
        "df['Text'] = [entry.lower() for entry in df['Text']]\n",
        "\n",
        "# Tokenization of words\n",
        "df['Text']= [word_tokenize(entry) for entry in df['Text']]\n",
        "# Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
        "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(df['Text']):\n",
        "    # Declaring Empty List to store the words that follow the rules for this step\n",
        "    Final_words = []\n",
        "    # Initializing WordNetLemmatizer()\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
        "    for word, tag in pos_tag(entry):\n",
        "        # Below condition is to check for Stop words and consider only alphabets\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
        "    df.loc[index,'text_final'] = str(Final_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RT3u44jzxvO"
      },
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(df['text_final'],df['Label'],test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSaxI3aGz1Mc"
      },
      "source": [
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAS1Kr75z2z5"
      },
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(df['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTDvNGYz4hy"
      },
      "source": [
        "pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwezLOg5z63_"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRUUnuGlz8uA"
      },
      "source": [
        "Naive = MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKh_yuAtz-1U"
      },
      "source": [
        "Naive = MultinomialNB()\n",
        "Naive.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
        "\n",
        "print(classification_report(Test_Y, predictions_NB ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv5nEwlQ0BI-"
      },
      "source": [
        "# Classifier - Algorithm - SVM\n",
        "# fit the training dataset on the classifier\n",
        "SVM = svm.SVC(C=1.2, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(Train_X_Tfidf,Train_Y)\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
        "\n",
        "print(classification_report(Test_Y, predictions_SVM ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqo4h2kcMZsQ"
      },
      "source": [
        "# ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8KYWZN0EQh"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmfeedLOMc2e"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "  \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-irony\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-irony\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29gCehOiN9CD"
      },
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSzeO572OXjw"
      },
      "source": [
        "def preprocess(text):\n",
        "    new_text = [\n",
        "    ]\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fns4LgYVMhon"
      },
      "source": [
        "task='irony'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "labels=[]\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "result = []\n",
        "\n",
        "for j in range(len(df)-1):\n",
        "  text = df['text'][j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)\n",
        "      #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxbKU_nURvLi",
        "outputId": "c0602e38-8173-4d7b-d76d-0d369998ee44"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3815"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrVADjytRx7h",
        "outputId": "731d7e97-5ed5-413c-ab76-f8090d0bca23"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(df)-1):\n",
        "  if(result[i]==df['label'][i]):\n",
        "    count +=1\n",
        "print((count*100)/(len(df)-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91.90039318479685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjSFEpLte6dy"
      },
      "source": [
        "test = []\n",
        "for i in range(3815):\n",
        "  test.append(df['label'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwmR9Hd2c2Vj",
        "outputId": "c058a571-a2ce-45b3-f306-37ce1c147d84"
      },
      "source": [
        "print(classification_report(test, result ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      1915\n",
            "           1       0.91      0.93      0.92      1900\n",
            "\n",
            "    accuracy                           0.92      3815\n",
            "   macro avg       0.92      0.92      0.92      3815\n",
            "weighted avg       0.92      0.92      0.92      3815\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4QCxzM3fzRa"
      },
      "source": [
        "# Experimenting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bPrTN099hs64"
      },
      "source": [
        "i = df[1]\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VMFZTfufywm",
        "outputId": "d55efaf8-856e-46ea-e41f-75d1fd3a4876"
      },
      "source": [
        "# Equal irony and non irony\n",
        "# initially irony = 1916 and non irony = 1900\n",
        "ir = [] #irony label\n",
        "ni = [] # non irony label\n",
        "irt =[] # irony text\n",
        "nit = [] # non irony text\n",
        "for i in range(3816):\n",
        "  if df['label'][i] == 0:\n",
        "    ir.append(df['label'][i])\n",
        "    irt.append(df['text'][i])\n",
        "  else:\n",
        "    ni.append(df['label'][i])\n",
        "    nit.append(df['text'][i])\n",
        "# print(\"irony = \", ir,\" Non Irony = \", ni)\n",
        "x = [] # label\n",
        "y = [] # text\n",
        "for i in range(1900):\n",
        "  x.append(ir[i])\n",
        "  y.append(irt[i])\n",
        "  x.append(ni[i])\n",
        "  y.append(nit[i])\n",
        "print(len(x))\n",
        "# shuffling the dataset\n",
        "import random\n",
        "temp = list(zip(x, y))\n",
        "random.shuffle(temp)\n",
        "x, y = zip(*temp)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw41uFBzhvVF"
      },
      "source": [
        "task='irony'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "labels=[]\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "result = []\n",
        "\n",
        "for j in range(3800):\n",
        "  text = y[j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)\n",
        "      #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn3rZHsHh5yH",
        "outputId": "b849ccd9-a9b8-4ad6-b59c-ac3973038dd1"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3800"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqwwZC8EiYnY",
        "outputId": "ee932aa2-60c9-4c0f-efdd-c2855831420f"
      },
      "source": [
        "count = 0\n",
        "for i in range(3800):\n",
        "  if(result[i]==x[i]):\n",
        "    count +=1\n",
        "print((count*100)/3800)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.86842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB17jt77igz0",
        "outputId": "5b8d73a9-16ab-48a2-c9f5-f114ee4487af"
      },
      "source": [
        "print(classification_report(x, result ))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92      1900\n",
            "           1       0.91      0.93      0.92      1900\n",
            "\n",
            "    accuracy                           0.92      3800\n",
            "   macro avg       0.92      0.92      0.92      3800\n",
            "weighted avg       0.92      0.92      0.92      3800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE0FTmYrrxp-"
      },
      "source": [
        "Trying with 3000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4uv6bFanm6M"
      },
      "source": [
        "# Trying with less dataset (3000)\n",
        "\n",
        "task='irony'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "labels=[]\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "result = []\n",
        "\n",
        "for j in range(3000):\n",
        "  text = y[j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)\n",
        "      #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv9c9ft7ntFd",
        "outputId": "c0725aae-ac8e-44cc-accf-e2100fbafe90"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S86LLoNKnynA",
        "outputId": "8452dd26-e0ad-4d28-a946-63613011e358"
      },
      "source": [
        "count = 0\n",
        "for i in range(3000):\n",
        "  if(result[i]==x[i]):\n",
        "    count +=1\n",
        "print((count*100)/3000)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.93333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ibKpMMnyg_",
        "outputId": "b8fe66f2-b161-4ec9-d072-a8d66336cdf3"
      },
      "source": [
        "print(classification_report(x[:3000], result))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      1490\n",
            "           1       0.91      0.93      0.92      1510\n",
            "\n",
            "    accuracy                           0.92      3000\n",
            "   macro avg       0.92      0.92      0.92      3000\n",
            "weighted avg       0.92      0.92      0.92      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMZCiNjhqHuf"
      },
      "source": [
        "Trying with 2500 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfttfsDGpzrN"
      },
      "source": [
        "result = []\n",
        "\n",
        "for j in range(2500):\n",
        "  text = y[j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whJm0MgcqOdi",
        "outputId": "1f7e46ce-3808-4481-b34e-7580d137fb35"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Di_-fgOqOah",
        "outputId": "b719240c-6b64-4e74-bd28-cd8717afb3e0"
      },
      "source": [
        "count = 0\n",
        "for i in range(2500):\n",
        "  if(result[i]==x[i]):\n",
        "    count +=1\n",
        "print((count*100)/2500)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hFUaYQgqN1A",
        "outputId": "1c1963cf-a8c9-4dbb-b099-42a16ac46948"
      },
      "source": [
        "print(classification_report(x[:2500], result))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      1234\n",
            "           1       0.91      0.93      0.92      1266\n",
            "\n",
            "    accuracy                           0.92      2500\n",
            "   macro avg       0.92      0.92      0.92      2500\n",
            "weighted avg       0.92      0.92      0.92      2500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHcMXDRkuRXD"
      },
      "source": [
        "Trying with 2800 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MG7c00GuQqx"
      },
      "source": [
        "result = []\n",
        "\n",
        "for j in range(2800):\n",
        "  text = y[j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M097flDVuZzu",
        "outputId": "e473465d-8e02-4385-df20-16c59191745e"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2800"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35A7Iv_1uZwY",
        "outputId": "6311c46e-dba0-4597-b60f-97fe80a82f3c"
      },
      "source": [
        "count = 0\n",
        "for i in range(2800):\n",
        "  if(result[i]==x[i]):\n",
        "    count +=1\n",
        "print((count*100)/2800)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.89285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C77D9oEuZnU",
        "outputId": "b4e0603f-e570-45d3-da97-159fc18eaa4a"
      },
      "source": [
        "print(classification_report(x[:2800], result))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92      1385\n",
            "           1       0.91      0.93      0.92      1415\n",
            "\n",
            "    accuracy                           0.92      2800\n",
            "   macro avg       0.92      0.92      0.92      2800\n",
            "weighted avg       0.92      0.92      0.92      2800\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRaevbvH0Lnh"
      },
      "source": [
        "trying with 2300 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7zuyubl0LHT"
      },
      "source": [
        "result = []\n",
        "\n",
        "for j in range(2300):\n",
        "  text = y[j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um_p0uBK0VXk",
        "outputId": "11ed8af5-a499-4b89-e559-7560f0d9ee07"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2300"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nSHFGHS0RTB",
        "outputId": "50eed5c5-b719-4db8-961e-07c686684ca4"
      },
      "source": [
        "count = 0\n",
        "for i in range(2300):\n",
        "  if(result[i]==x[i]):\n",
        "    count +=1\n",
        "print((count*100)/2300)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91.95652173913044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yUWrSML0W8F",
        "outputId": "a2d06752-7ba1-4806-ee8c-1e5ac8dd8502"
      },
      "source": [
        "print(classification_report(x[:2300], result))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      1142\n",
            "           1       0.91      0.93      0.92      1158\n",
            "\n",
            "    accuracy                           0.92      2300\n",
            "   macro avg       0.92      0.92      0.92      2300\n",
            "weighted avg       0.92      0.92      0.92      2300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRz1ioA-96aR"
      },
      "source": [
        "# DATASET WITH EMOJI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bZuMwU6-B91"
      },
      "source": [
        "# dataframe = pd.read_csv(r\"/content/data with emoji.txt\",delimiter=\"\\t\")\n",
        "# dataframe.to_csv(\"data with emoji.csv\", encoding='utf-8', index=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3-guhaNA67d"
      },
      "source": [
        "df1 = pd.read_csv(r\"/content/data with emoji.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nye9ArhhBSnh",
        "outputId": "7f11c2c4-fe96-46da-e85d-51755a8c1681"
      },
      "source": [
        "df1['Tweet text'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@mrdahl87 We are rumored to have talked to Erv's agent... and the Angels asked about Ed Escobar... that's hardly nothing    ;)\""
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QclSyNKB6Vg"
      },
      "source": [
        "result = []\n",
        "\n",
        "for j in range(len(df1)):\n",
        "  text = df1['Tweet text'][j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0YpjDezCJdE",
        "outputId": "a1af92f3-3955-4a2c-c2b6-1db976aab9b8"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3817"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "L1HmqGXzEE8G",
        "outputId": "bbfb6494-38d6-40af-8847-6e5844e84a35"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet index</th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sweet United Nations video. Just in time for C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left I'm dying over here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tweet index  Label                                         Tweet text\n",
              "0            1      1  Sweet United Nations video. Just in time for C...\n",
              "1            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
              "2            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
              "3            4      0                3 episodes left I'm dying over here\n",
              "4            5      1  I can't breathe! was chosen as the most notabl..."
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8izKfa54CJRE",
        "outputId": "cf739e3e-5c32-4f60-94b4-d74b2b470407"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(df1)):\n",
        "  if(result[i]==df1['Label'][i]):\n",
        "    count +=1\n",
        "print((count*100)/len(df1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92.58580036678019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rllL63CzCJGi"
      },
      "source": [
        "test = []\n",
        "for i in range(3817):\n",
        "  test.append(df1['Label'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmzTvCfECbof",
        "outputId": "0018a2af-3a87-4bb9-9592-e5e8ba5a5e50"
      },
      "source": [
        "print(classification_report(test, result ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.92      1916\n",
            "           1       0.91      0.95      0.93      1901\n",
            "\n",
            "    accuracy                           0.93      3817\n",
            "   macro avg       0.93      0.93      0.93      3817\n",
            "weighted avg       0.93      0.93      0.93      3817\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTZ7UYzzEgnf"
      },
      "source": [
        "# DATASET WITH EMOJI AND HASHTAG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt2L29UeEpYa"
      },
      "source": [
        "# dataframe = pd.read_csv(r\"/content/data with hashtag and emoji.txt\",delimiter=\"\\t\")\n",
        "# dataframe.to_csv(\"data with hashtag and emoji.csv\", encoding='utf-8', index=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtlOVbvHEpVT"
      },
      "source": [
        "df2 = pd.read_csv(r\"/content/data with hashtag and emoji.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvwj6HhlEpRj"
      },
      "source": [
        "result = []\n",
        "\n",
        "for j in range(len(df2)):\n",
        "  text = df1['Tweet text'][j]\n",
        "  text = preprocess(text)\n",
        "  encoded_input = tokenizer(text, return_tensors='pt')\n",
        "  output = model(**encoded_input)\n",
        "  scores = output[0][0].detach().numpy()\n",
        "  scores = softmax(scores)\n",
        "\n",
        "  ranking = np.argsort(scores)\n",
        "  ranking = ranking[::-1]\n",
        "  for i in range(scores.shape[0]):\n",
        "      l = labels[ranking[i]]\n",
        "      s = scores[ranking[i]]\n",
        "      if(s>0.5):\n",
        "          if l == 'non_irony':\n",
        "            result.append(0)\n",
        "          else:\n",
        "            result.append(1)\n",
        "  if j%500 == 0:\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYb1ezPMEpPn",
        "outputId": "65d09e10-3d3a-4177-bd2d-cb9408b8d558"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3817"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AH2h8GKFO3m",
        "outputId": "ce76ee55-4db5-4cff-8953-e6b3489938f0"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet index</th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sweet United Nations video. Just in time for C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left I'm dying over here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>I can't breathe! was chosen as the most notabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tweet index  Label                                         Tweet text\n",
              "0            1      1  Sweet United Nations video. Just in time for C...\n",
              "1            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
              "2            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
              "3            4      0                3 episodes left I'm dying over here\n",
              "4            5      1  I can't breathe! was chosen as the most notabl..."
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVp98WqRFSxz",
        "outputId": "37a9b6ec-6f59-44ea-d511-c6490acc14e1"
      },
      "source": [
        "count = 0\n",
        "for i in range(len(df2)):\n",
        "  if(result[i]==df2['Label'][i]):\n",
        "    count +=1\n",
        "print((count*100)/len(df2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92.58580036678019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDAP7CMuFSnm"
      },
      "source": [
        "test = []\n",
        "for i in range(3817):\n",
        "  test.append(df2['Label'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZfGF4_Fbdu",
        "outputId": "3339c5ab-9d85-456f-b9cc-0567b94e0065"
      },
      "source": [
        "print(classification_report(test, result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.90      0.92      1916\n",
            "           1       0.91      0.95      0.93      1901\n",
            "\n",
            "    accuracy                           0.93      3817\n",
            "   macro avg       0.93      0.93      0.93      3817\n",
            "weighted avg       0.93      0.93      0.93      3817\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIdKrVufXzDH"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfVJJgOA_eGw",
        "outputId": "f086b30d-a14a-4549-f0cd-4d91b1ec9412"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# MOUNT google drive onto COLAB notebook\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# install and import BertTokenizer\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# import tensor datasets for creating batches of the data\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# define seed for training\n",
        "SEED = 2021\n",
        "\n",
        "# Set seed for all randoms\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF6q4VxNIjl6"
      },
      "source": [
        "'''SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = False'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOPNi3X82xBD"
      },
      "source": [
        "df = pd.read_csv(\"/content/data.csv\", encoding = \"ISO-8859-1\", header=None)\n",
        "#import random\n",
        "#df = df.sample(frac=1)\n",
        "df.columns=[\"LABEL\", \"TEXT\"]\n",
        "df = df.sample(n = 3817, random_state=SEED).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "AtuGQXu557bt",
        "outputId": "252ac90d-9bcc-4585-91cd-b77da6c06335"
      },
      "source": [
        "df[3000:3100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>0</td>\n",
              "      <td>Choose your words carefully hurting someone fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3001</th>\n",
              "      <td>0</td>\n",
              "      <td>I pray God comes back in America and saves us ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002</th>\n",
              "      <td>0</td>\n",
              "      <td>Day off should be snuggled on the sofa doing n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3003</th>\n",
              "      <td>1</td>\n",
              "      <td>Love that I can count on people.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3004</th>\n",
              "      <td>1</td>\n",
              "      <td>http://t.co/xMzzKi6kn6 &lt;&lt; This should be Chris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3095</th>\n",
              "      <td>0</td>\n",
              "      <td>Packers fans on Twitter are on full meltdown m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3096</th>\n",
              "      <td>0</td>\n",
              "      <td>@Devin_Heroux @CBCEyeopener @downtowncalgary w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3097</th>\n",
              "      <td>1</td>\n",
              "      <td>Well throwing up at 6:00 am is always fun :whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3098</th>\n",
              "      <td>0</td>\n",
              "      <td>@JakePlank24 do you not work at the dirty bird...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3099</th>\n",
              "      <td>0</td>\n",
              "      <td>alot-still not sussed out how yo keep in touc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      LABEL                                               TEXT\n",
              "3000      0  Choose your words carefully hurting someone fe...\n",
              "3001      0  I pray God comes back in America and saves us ...\n",
              "3002      0  Day off should be snuggled on the sofa doing n...\n",
              "3003      1                  Love that I can count on people. \n",
              "3004      1  http://t.co/xMzzKi6kn6 << This should be Chris...\n",
              "...     ...                                                ...\n",
              "3095      0  Packers fans on Twitter are on full meltdown m...\n",
              "3096      0  @Devin_Heroux @CBCEyeopener @downtowncalgary w...\n",
              "3097      1  Well throwing up at 6:00 am is always fun :whi...\n",
              "3098      0  @JakePlank24 do you not work at the dirty bird...\n",
              "3099      0   alot-still not sussed out how yo keep in touc...\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 300,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAVsgwCp3NAV"
      },
      "source": [
        "import re\n",
        "def tokenize_truncate(sentence, tokenizer, max_input_length):  \n",
        "    sentence= re.sub(r\"(@[A-Za-z0–9_]+)|[^\\w\\s]|#|http\\S+\", \"\", sentence)\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = [tokenizer.cls_token] + tokens[:max_input_length-2] + [tokenizer.sep_token]\n",
        "    return tokens\n",
        "\n",
        "# Create BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "max_input_length=64\n",
        "# 64\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(tokenize_truncate(sent, tokenizer, max_input_length)) for sent in df.TEXT.values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaIvEOLd3Trg"
      },
      "source": [
        "def get_data_tensors(input_ids, labels, train_test_ratio=0.375, train_valid_ratio=0.3, max_input_length=64):\n",
        "    # Split data into training, testing and validation sets\n",
        "    train_text, test_inputs, train_label, test_labels = train_test_split(input_ids, labels, \n",
        "                                                                random_state=SEED, test_size=train_test_ratio)\n",
        "    train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_text, train_label, \n",
        "                                                                random_state=SEED, test_size=train_valid_ratio)\n",
        "\n",
        "    # Pad data into arrays of length max_input_length\n",
        "    train_inputs = pad_sequences(train_inputs, maxlen=max_input_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    validation_inputs = pad_sequences(validation_inputs, maxlen=max_input_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    test_inputs = pad_sequences(test_inputs, maxlen=max_input_length, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # Convert inputs and labels into Long and Float tensors\n",
        "    train_inputs = torch.LongTensor(train_inputs)\n",
        "    validation_inputs = torch.LongTensor(validation_inputs)\n",
        "    train_labels = torch.FloatTensor(train_labels.to_list())\n",
        "    validation_labels = torch.FloatTensor(validation_labels.to_list())\n",
        "\n",
        "    test_inputs = torch.LongTensor(test_inputs)\n",
        "    test_labels = torch.FloatTensor(test_labels.to_list())\n",
        "    return train_inputs, train_labels,validation_inputs, validation_labels, test_inputs, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEh7KNsm3YuD"
      },
      "source": [
        "# Convert Tensors to batches\n",
        "def get_loaders(train_inputs, train_labels, validation_data, validation_labels):\n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    validation_data = TensorDataset(validation_inputs, validation_labels)\n",
        "    validation_sampler = SequentialSampler(validation_data)\n",
        "    validation_loader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "    return train_loader, validation_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIo5fKLx3bhC"
      },
      "source": [
        "\n",
        "class Feedforward(torch.nn.Module):\n",
        "  def __init__(self, layers, embedding_dim):\n",
        "    super(Feedforward, self).__init__()\n",
        "\n",
        "    # get vocabulary list length from BERT tokenizer\n",
        "    vocab_size=len(tokenizer.vocab.keys())\n",
        "\n",
        "    # initialize embedding layer\n",
        "    self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # create list for NN layers and activation layers\n",
        "    self.fc = torch.nn.ModuleList()\n",
        "    self.activations = []\n",
        "\n",
        "    # append first layer\n",
        "    self.fc.append(torch.nn.Linear(embedding_dim*layers[0], layers[0]))\n",
        "    # self.fc.append(torch.nn.RNN(embedding_dim, layers[0]))\n",
        "    for i in range(len(layers)-1):\n",
        "      # Append activation function for previous layer\n",
        "      self.activations.append(torch.nn.ReLU())\n",
        "      #self.activations.append(torch.nn.Softmax())\n",
        "      # append layer with given dimensions\n",
        "      self.fc.append(torch.nn.Linear(layers[i], layers[i+1]))\n",
        "      print(layers[i], layers[i+1])\n",
        "\n",
        "    # # declare dropout layer function\n",
        "    self.dropout = torch.nn.Dropout(0.2)\n",
        "            \n",
        "  def forward(self, x):\n",
        "    # Apply embeddding layer at beginnning and then train model\n",
        "    y = self.embeddings(x).squeeze()\n",
        "\n",
        "    for layer in range(len(self.fc)):\n",
        "      if layer!=len(self.fc)-1:\n",
        "        # Apply activation function for all layers other than the last\n",
        "        y= self.dropout(self.activations[layer](self.fc[layer](y)))\n",
        "      else:\n",
        "        # No activation function since we are using BCEWithLogitsLoss\n",
        "        y= self.fc[layer](y)\n",
        "\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwoy-ZGP3g2w"
      },
      "source": [
        "def evaluate_model(inputs, labels, data_name=\"\"):\n",
        "  \"\"\"\n",
        "  Model to evaluate model given inputs(text) and labels\n",
        "  :param inputs: TEXT to be classified\n",
        "  :param labels: Actual values of the LABELS to be predicted\n",
        "  :param data_name: Name of data being evaluated \n",
        "  \"\"\"\n",
        "  # Initiate model in evaluation mode\n",
        "  model.eval()\n",
        "  # Squeeze output to 1D\n",
        "  pred_labels = model(inputs)\n",
        "  # pred_labels = model(inputs).squeeze(1)\n",
        "  # pred_labels=torch.tensor(pred_labels)\n",
        "  pred_labels = (pred_labels>THRESHOLD).float()\n",
        "  # use criterion to calculate loss\n",
        "  before_train = criterion(pred_labels.squeeze(), labels)\n",
        "  print(f'{data_name}\\n\\tLoss: {before_train.item()}')\n",
        "  print(f\"\\tAccuracy: {accuracy_score(pred_labels, labels)}\")\n",
        "  return before_train.item(), accuracy_score(pred_labels, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QywgXEp3jp4",
        "outputId": "2c62a82e-640b-4be4-c877-045a9b25b438"
      },
      "source": [
        "# Convert dataset 0s and 4s to 0s and 1s\n",
        "label_dict={0: 0, 1: 1}\n",
        "# Batch size for DataLoader. For fine-tuning BERT on a specific task, recommended size is 16 or 32\n",
        "batch_size = 128\n",
        "# NN hyper-parameters\n",
        "nn_topology = (max_input_length, 128, 64, 32 , 1)\n",
        "THRESHOLD=0\n",
        "# 0.5, 45\n",
        "\n",
        "df.LABEL= df.LABEL.replace(label_dict)\n",
        "df['LABEL'] = df['LABEL'].replace({0:0, 1:1})\n",
        "train_inputs, train_labels,validation_inputs, validation_labels, test_inputs, test_labels = get_data_tensors(input_ids, df.LABEL, train_test_ratio=0.375, train_valid_ratio=0.3, max_input_length = max_input_length)\n",
        "print(f\"Number of training: {len(train_inputs)}\")\n",
        "print(f\"Number of validation: {len(validation_inputs)}\")\n",
        "print(f\"Number of testing: {len(test_inputs)}\")\n",
        "\n",
        "train_loader, validation_loader = get_loaders(train_inputs, train_labels, validation_inputs, validation_labels)\n",
        "model = Feedforward(nn_topology,1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training: 1669\n",
            "Number of validation: 716\n",
            "Number of testing: 1432\n",
            "64 128\n",
            "128 64\n",
            "64 32\n",
            "32 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKWwSb2u3mt-",
        "outputId": "89ab6200-c1d6-4cbb-bb20-93f6e1c7014f"
      },
      "source": [
        "\n",
        "\n",
        "# 45 epochs with 0.5, 15 with 0.01\n",
        "EPOCHS = 70\n",
        "LEARNING_RATE=0.01\n",
        "# EPOCHS = 15\n",
        "# 20\n",
        "# LEARNING_RATE=0.1\n",
        "validation_accuracy = []\n",
        "train_accuracy = []\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr =LEARNING_RATE)\n",
        "\n",
        "# Pre-training evaluation\n",
        "evaluate_model(validation_inputs, validation_labels, data_name=\"Validation\")\n",
        "# train_accuracy=[]\n",
        "# validation_accuracy=[]\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss=0\n",
        "    valid_loss=0\n",
        "    # model.train()\n",
        "    for data, target in train_loader:\n",
        "          # clear the gradients of all optimized variables\n",
        "          optimizer.zero_grad()\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model(data)\n",
        "          # calculate the loss\n",
        "          loss = criterion(output.squeeze(), target)\n",
        "          # backward pass: compute gradient of the loss with respect to model parameters\n",
        "          loss.backward()\n",
        "          # perform a single optimization step (parameter update)\n",
        "          optimizer.step()\n",
        "          # update running training loss\n",
        "          train_loss += loss.item()*data.size(0)\n",
        "          \n",
        "    loss, acc = evaluate_model(validation_inputs, validation_labels, data_name=f\"{epoch}: Validation\")\n",
        "    validation_accuracy.append(acc)\n",
        "\n",
        "    loss, acc = evaluate_model(train_inputs, train_labels, data_name=f\"{epoch}: Train\")\n",
        "    train_accuracy.append(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "0: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "0: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "1: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "1: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "2: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "2: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "3: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "3: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "4: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "4: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "5: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "5: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "6: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "6: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "7: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "7: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "8: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "8: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "9: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "9: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "10: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "10: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "11: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "11: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "12: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "12: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "13: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "13: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "14: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "14: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "15: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "15: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "16: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "16: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "17: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "17: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "18: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "18: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "19: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "19: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "20: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "20: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "21: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "21: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "22: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "22: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "23: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "23: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "24: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "24: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "25: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "25: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "26: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "26: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "27: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "27: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "28: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "28: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "29: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "29: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "30: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "30: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "31: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "31: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "32: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "32: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "33: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "33: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "34: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "34: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n",
            "35: Validation\n",
            "\tLoss: 0.6931473612785339\n",
            "\tAccuracy: 0.4958100558659218\n",
            "35: Train\n",
            "\tLoss: 0.6931474208831787\n",
            "\tAccuracy: 0.5062911923307369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1wNgkJOEyH2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}